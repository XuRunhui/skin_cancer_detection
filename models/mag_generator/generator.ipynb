{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 3\n",
    "ndf = 64\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, nc = 3, ndf = 64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 8, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.RandomRotation(30),  # 随机旋转 -30 到 30 度\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # 以 50% 概率水平翻转\n",
    "        transforms.RandomVerticalFlip(p=0.5),  # 以 50% 概率垂直翻转\n",
    "        # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0),  # 随机改变亮度、对比度和饱和度\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, hdf5_file, transform=None, target_label=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            target_label (int, optional): Target label to filter and load specific class images.\n",
    "        \"\"\"\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.hdf5_file = h5py.File(hdf5_file, 'r')\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 只保留目标标签的数据\n",
    "        self.annotations = self.annotations[self.annotations['target'] == target_label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        isic_id = self.annotations.iloc[idx][\"isic_id\"]\n",
    "        if isic_id in self.hdf5_file:\n",
    "            image = self.hdf5_file[isic_id]\n",
    "            # Check if the data is numerical before conversion\n",
    "            image_data = image[()]\n",
    "            # 将字节字符串解码为图像\n",
    "            image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "                \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4163120/3731011086.py:10: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.annotations = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytransform = get_transform()\n",
    "dataset = CustomDataset(csv_file=\"../../data/train-metadata.csv\", hdf5_file=\"../../data/train-image.hdf5\", transform=mytransform)\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
    "                                         shuffle=True, num_workers=16)\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:1\")\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "# for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "data = next(iter(dataloader))\n",
    "print(data[0].shape)\n",
    "netD.zero_grad()\n",
    "real_cpu = data[0].to(device)\n",
    "batch_size = real_cpu.size(0)\n",
    "label = torch.full((batch_size,), 1,\n",
    "                        dtype=real_cpu.dtype, device=device)\n",
    "\n",
    "output = netD(real_cpu)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf =64\n",
    "nz = 100\n",
    "ngpu = 1\n",
    "nc = 3\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf * 4,     ngf*2, 4, 4, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            # #128*128\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            #256*256\n",
    "            nn.ConvTranspose2d( ngf,      nc, 5, 1, 2, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "nz = 100\n",
    "ngf = 64\n",
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "fake = netG(noise)\n",
    "print(fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = 64\n",
    "nz = 100\n",
    "nc = 3\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:1\")\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf * 4,     ngf*2, 4, 4, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            # #128*128\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            #256*256\n",
    "            nn.ConvTranspose2d( ngf,      nc, 5, 1, 2, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "generators = [net for net in os.listdir() if net.startswith('netG') and net.endswith('.pth')]\n",
    "\n",
    "# path = \"./netG_epoch_30.pth\"\n",
    "for path in generators:\n",
    "    netG = Generator(ngpu).to(device)\n",
    "    netG.apply(weights_init)\n",
    "    if path!= '':\n",
    "        netG.load_state_dict(torch.load(path))\n",
    "        print(\"Loaded model from {}\".format(path))\n",
    "    torch.manual_seed(999)\n",
    "    for i in range(100):\n",
    "        fixed_noise = torch.randn(1, nz, 1, 1, device=device)\n",
    "        # print(fixed_noise)\n",
    "        fake = netG(fixed_noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "                        f'./images/{path}_{i}.png',\n",
    "                        normalize=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.4475]],\n",
      "\n",
      "         [[ 0.9223]],\n",
      "\n",
      "         [[-0.2639]],\n",
      "\n",
      "         [[ 2.2199]],\n",
      "\n",
      "         [[-1.7821]],\n",
      "\n",
      "         [[-1.5525]],\n",
      "\n",
      "         [[-0.0510]],\n",
      "\n",
      "         [[ 2.0793]],\n",
      "\n",
      "         [[ 1.8283]],\n",
      "\n",
      "         [[ 1.0873]],\n",
      "\n",
      "         [[ 1.0379]],\n",
      "\n",
      "         [[-0.6214]],\n",
      "\n",
      "         [[-0.5439]],\n",
      "\n",
      "         [[-0.9079]],\n",
      "\n",
      "         [[ 0.1143]],\n",
      "\n",
      "         [[ 0.3452]],\n",
      "\n",
      "         [[ 0.4308]],\n",
      "\n",
      "         [[ 0.2358]],\n",
      "\n",
      "         [[ 0.5563]],\n",
      "\n",
      "         [[ 1.1140]],\n",
      "\n",
      "         [[ 1.5716]],\n",
      "\n",
      "         [[ 0.1618]],\n",
      "\n",
      "         [[ 0.5240]],\n",
      "\n",
      "         [[ 1.0051]],\n",
      "\n",
      "         [[-0.5359]],\n",
      "\n",
      "         [[ 0.4478]],\n",
      "\n",
      "         [[-0.3239]],\n",
      "\n",
      "         [[-0.4393]],\n",
      "\n",
      "         [[ 0.4730]],\n",
      "\n",
      "         [[ 0.3857]],\n",
      "\n",
      "         [[ 1.2216]],\n",
      "\n",
      "         [[-0.1880]],\n",
      "\n",
      "         [[-0.7251]],\n",
      "\n",
      "         [[ 1.2665]],\n",
      "\n",
      "         [[-1.6395]],\n",
      "\n",
      "         [[ 0.7707]],\n",
      "\n",
      "         [[-0.7572]],\n",
      "\n",
      "         [[ 0.3397]],\n",
      "\n",
      "         [[-0.3407]],\n",
      "\n",
      "         [[-0.8857]],\n",
      "\n",
      "         [[-0.5045]],\n",
      "\n",
      "         [[-0.5756]],\n",
      "\n",
      "         [[-0.4674]],\n",
      "\n",
      "         [[-2.0278]],\n",
      "\n",
      "         [[ 1.2254]],\n",
      "\n",
      "         [[ 1.3934]],\n",
      "\n",
      "         [[-0.9338]],\n",
      "\n",
      "         [[ 0.0337]],\n",
      "\n",
      "         [[-0.5621]],\n",
      "\n",
      "         [[-1.1542]],\n",
      "\n",
      "         [[ 0.3214]],\n",
      "\n",
      "         [[-0.3061]],\n",
      "\n",
      "         [[ 0.9022]],\n",
      "\n",
      "         [[-0.6621]],\n",
      "\n",
      "         [[ 1.1652]],\n",
      "\n",
      "         [[-0.4098]],\n",
      "\n",
      "         [[-1.5005]],\n",
      "\n",
      "         [[ 0.3867]],\n",
      "\n",
      "         [[ 0.7824]],\n",
      "\n",
      "         [[-0.1938]],\n",
      "\n",
      "         [[-0.4955]],\n",
      "\n",
      "         [[-0.7446]],\n",
      "\n",
      "         [[ 0.1337]],\n",
      "\n",
      "         [[ 1.3532]],\n",
      "\n",
      "         [[ 1.1171]],\n",
      "\n",
      "         [[ 0.0704]],\n",
      "\n",
      "         [[-0.7584]],\n",
      "\n",
      "         [[-1.2770]],\n",
      "\n",
      "         [[-0.6120]],\n",
      "\n",
      "         [[-0.7178]],\n",
      "\n",
      "         [[-1.1662]],\n",
      "\n",
      "         [[ 0.3123]],\n",
      "\n",
      "         [[ 1.8233]],\n",
      "\n",
      "         [[ 0.7978]],\n",
      "\n",
      "         [[ 0.5218]],\n",
      "\n",
      "         [[ 0.3400]],\n",
      "\n",
      "         [[-0.6960]],\n",
      "\n",
      "         [[ 0.7772]],\n",
      "\n",
      "         [[-0.4462]],\n",
      "\n",
      "         [[ 0.5116]],\n",
      "\n",
      "         [[ 0.8476]],\n",
      "\n",
      "         [[-1.7079]],\n",
      "\n",
      "         [[-1.3984]],\n",
      "\n",
      "         [[-0.0753]],\n",
      "\n",
      "         [[-0.2763]],\n",
      "\n",
      "         [[-1.7914]],\n",
      "\n",
      "         [[ 1.2617]],\n",
      "\n",
      "         [[-2.5930]],\n",
      "\n",
      "         [[ 1.4685]],\n",
      "\n",
      "         [[ 0.3581]],\n",
      "\n",
      "         [[ 0.2063]],\n",
      "\n",
      "         [[ 0.7789]],\n",
      "\n",
      "         [[ 0.6121]],\n",
      "\n",
      "         [[ 2.5837]],\n",
      "\n",
      "         [[-0.3854]],\n",
      "\n",
      "         [[-0.7566]],\n",
      "\n",
      "         [[-0.4501]],\n",
      "\n",
      "         [[ 1.4843]],\n",
      "\n",
      "         [[-1.3365]],\n",
      "\n",
      "         [[-0.4587]]]], device='cuda:1')\n",
      "tensor([[[[-0.4589]],\n",
      "\n",
      "         [[-0.2090]],\n",
      "\n",
      "         [[-0.1940]],\n",
      "\n",
      "         [[-2.1808]],\n",
      "\n",
      "         [[-0.0188]],\n",
      "\n",
      "         [[ 1.8213]],\n",
      "\n",
      "         [[ 3.1663]],\n",
      "\n",
      "         [[-1.0121]],\n",
      "\n",
      "         [[-0.6969]],\n",
      "\n",
      "         [[-1.1378]],\n",
      "\n",
      "         [[ 1.1904]],\n",
      "\n",
      "         [[ 0.0804]],\n",
      "\n",
      "         [[ 0.9519]],\n",
      "\n",
      "         [[-0.6610]],\n",
      "\n",
      "         [[-0.7526]],\n",
      "\n",
      "         [[-0.1869]],\n",
      "\n",
      "         [[ 3.0159]],\n",
      "\n",
      "         [[ 1.3436]],\n",
      "\n",
      "         [[ 0.8749]],\n",
      "\n",
      "         [[-0.7809]],\n",
      "\n",
      "         [[ 1.2137]],\n",
      "\n",
      "         [[-0.6001]],\n",
      "\n",
      "         [[-0.9502]],\n",
      "\n",
      "         [[-0.7551]],\n",
      "\n",
      "         [[ 0.1121]],\n",
      "\n",
      "         [[ 0.8858]],\n",
      "\n",
      "         [[-0.9379]],\n",
      "\n",
      "         [[-0.9908]],\n",
      "\n",
      "         [[ 2.2128]],\n",
      "\n",
      "         [[-0.8258]],\n",
      "\n",
      "         [[-1.2016]],\n",
      "\n",
      "         [[ 1.1341]],\n",
      "\n",
      "         [[ 0.1380]],\n",
      "\n",
      "         [[-0.7230]],\n",
      "\n",
      "         [[-1.6885]],\n",
      "\n",
      "         [[ 1.0681]],\n",
      "\n",
      "         [[ 0.7207]],\n",
      "\n",
      "         [[ 1.1055]],\n",
      "\n",
      "         [[ 0.2337]],\n",
      "\n",
      "         [[ 1.4257]],\n",
      "\n",
      "         [[-1.0754]],\n",
      "\n",
      "         [[ 1.3454]],\n",
      "\n",
      "         [[-0.2963]],\n",
      "\n",
      "         [[ 0.1024]],\n",
      "\n",
      "         [[-0.3378]],\n",
      "\n",
      "         [[ 0.4010]],\n",
      "\n",
      "         [[ 0.8446]],\n",
      "\n",
      "         [[-1.0707]],\n",
      "\n",
      "         [[-0.5484]],\n",
      "\n",
      "         [[ 0.3459]],\n",
      "\n",
      "         [[-0.0935]],\n",
      "\n",
      "         [[-0.4127]],\n",
      "\n",
      "         [[-0.4935]],\n",
      "\n",
      "         [[ 0.9104]],\n",
      "\n",
      "         [[-1.2990]],\n",
      "\n",
      "         [[-1.5384]],\n",
      "\n",
      "         [[-1.1526]],\n",
      "\n",
      "         [[ 0.1204]],\n",
      "\n",
      "         [[-1.0348]],\n",
      "\n",
      "         [[ 0.1253]],\n",
      "\n",
      "         [[ 0.0094]],\n",
      "\n",
      "         [[-1.2535]],\n",
      "\n",
      "         [[-1.1301]],\n",
      "\n",
      "         [[ 0.8796]],\n",
      "\n",
      "         [[-0.3484]],\n",
      "\n",
      "         [[ 0.0551]],\n",
      "\n",
      "         [[ 0.5159]],\n",
      "\n",
      "         [[ 1.5258]],\n",
      "\n",
      "         [[-0.3123]],\n",
      "\n",
      "         [[-0.2206]],\n",
      "\n",
      "         [[ 0.3869]],\n",
      "\n",
      "         [[ 0.0884]],\n",
      "\n",
      "         [[-0.5771]],\n",
      "\n",
      "         [[-0.1504]],\n",
      "\n",
      "         [[-0.4713]],\n",
      "\n",
      "         [[-0.6335]],\n",
      "\n",
      "         [[-0.3108]],\n",
      "\n",
      "         [[ 0.1290]],\n",
      "\n",
      "         [[ 1.9154]],\n",
      "\n",
      "         [[-1.7604]],\n",
      "\n",
      "         [[ 1.4313]],\n",
      "\n",
      "         [[ 0.4106]],\n",
      "\n",
      "         [[ 0.8698]],\n",
      "\n",
      "         [[-0.3256]],\n",
      "\n",
      "         [[ 1.2362]],\n",
      "\n",
      "         [[ 1.3797]],\n",
      "\n",
      "         [[ 0.4477]],\n",
      "\n",
      "         [[ 0.2594]],\n",
      "\n",
      "         [[ 0.0386]],\n",
      "\n",
      "         [[-1.8632]],\n",
      "\n",
      "         [[-2.3411]],\n",
      "\n",
      "         [[ 1.0634]],\n",
      "\n",
      "         [[-1.8901]],\n",
      "\n",
      "         [[-0.0334]],\n",
      "\n",
      "         [[-0.4789]],\n",
      "\n",
      "         [[-0.9236]],\n",
      "\n",
      "         [[-1.6089]],\n",
      "\n",
      "         [[-1.1509]],\n",
      "\n",
      "         [[ 0.7262]],\n",
      "\n",
      "         [[-1.1733]]]], device='cuda:1')\n",
      "tensor([[[[-0.4651]],\n",
      "\n",
      "         [[ 0.6558]],\n",
      "\n",
      "         [[-1.1223]],\n",
      "\n",
      "         [[-0.7101]],\n",
      "\n",
      "         [[-1.6050]],\n",
      "\n",
      "         [[-0.3332]],\n",
      "\n",
      "         [[ 1.3142]],\n",
      "\n",
      "         [[-0.4115]],\n",
      "\n",
      "         [[-1.8347]],\n",
      "\n",
      "         [[ 0.4087]],\n",
      "\n",
      "         [[ 0.1357]],\n",
      "\n",
      "         [[-0.9301]],\n",
      "\n",
      "         [[ 0.7315]],\n",
      "\n",
      "         [[-0.4711]],\n",
      "\n",
      "         [[-0.0368]],\n",
      "\n",
      "         [[-1.1184]],\n",
      "\n",
      "         [[-0.7049]],\n",
      "\n",
      "         [[ 0.2346]],\n",
      "\n",
      "         [[-0.8314]],\n",
      "\n",
      "         [[-1.5233]],\n",
      "\n",
      "         [[ 1.0481]],\n",
      "\n",
      "         [[ 0.4710]],\n",
      "\n",
      "         [[-0.7475]],\n",
      "\n",
      "         [[-1.0087]],\n",
      "\n",
      "         [[-0.6010]],\n",
      "\n",
      "         [[ 1.3648]],\n",
      "\n",
      "         [[ 1.1318]],\n",
      "\n",
      "         [[-1.1416]],\n",
      "\n",
      "         [[ 0.2664]],\n",
      "\n",
      "         [[-0.2057]],\n",
      "\n",
      "         [[-0.9596]],\n",
      "\n",
      "         [[-2.0613]],\n",
      "\n",
      "         [[-0.3287]],\n",
      "\n",
      "         [[ 0.3467]],\n",
      "\n",
      "         [[ 0.0969]],\n",
      "\n",
      "         [[-0.1594]],\n",
      "\n",
      "         [[-1.5527]],\n",
      "\n",
      "         [[-1.6187]],\n",
      "\n",
      "         [[ 0.2590]],\n",
      "\n",
      "         [[ 1.2789]],\n",
      "\n",
      "         [[-0.6116]],\n",
      "\n",
      "         [[ 0.8401]],\n",
      "\n",
      "         [[-2.2108]],\n",
      "\n",
      "         [[-1.4626]],\n",
      "\n",
      "         [[-0.4964]],\n",
      "\n",
      "         [[ 1.8062]],\n",
      "\n",
      "         [[-0.3238]],\n",
      "\n",
      "         [[-0.6401]],\n",
      "\n",
      "         [[-0.6445]],\n",
      "\n",
      "         [[ 0.5004]],\n",
      "\n",
      "         [[ 0.0675]],\n",
      "\n",
      "         [[ 0.4069]],\n",
      "\n",
      "         [[-0.1080]],\n",
      "\n",
      "         [[-0.1379]],\n",
      "\n",
      "         [[-1.8077]],\n",
      "\n",
      "         [[-1.9182]],\n",
      "\n",
      "         [[ 1.0913]],\n",
      "\n",
      "         [[ 0.7977]],\n",
      "\n",
      "         [[ 0.9429]],\n",
      "\n",
      "         [[-0.4753]],\n",
      "\n",
      "         [[-0.7790]],\n",
      "\n",
      "         [[-1.0154]],\n",
      "\n",
      "         [[-0.9284]],\n",
      "\n",
      "         [[ 1.1288]],\n",
      "\n",
      "         [[ 0.0750]],\n",
      "\n",
      "         [[ 0.8276]],\n",
      "\n",
      "         [[-0.7442]],\n",
      "\n",
      "         [[-0.7287]],\n",
      "\n",
      "         [[ 1.6311]],\n",
      "\n",
      "         [[ 1.6525]],\n",
      "\n",
      "         [[-0.1415]],\n",
      "\n",
      "         [[-0.4109]],\n",
      "\n",
      "         [[ 0.7558]],\n",
      "\n",
      "         [[ 0.4064]],\n",
      "\n",
      "         [[-0.1154]],\n",
      "\n",
      "         [[-2.6267]],\n",
      "\n",
      "         [[-0.9249]],\n",
      "\n",
      "         [[-0.0456]],\n",
      "\n",
      "         [[ 1.7890]],\n",
      "\n",
      "         [[ 0.5753]],\n",
      "\n",
      "         [[ 1.9845]],\n",
      "\n",
      "         [[-0.1188]],\n",
      "\n",
      "         [[-0.6359]],\n",
      "\n",
      "         [[-2.5918]],\n",
      "\n",
      "         [[ 0.1667]],\n",
      "\n",
      "         [[ 1.9479]],\n",
      "\n",
      "         [[ 0.6918]],\n",
      "\n",
      "         [[ 0.7342]],\n",
      "\n",
      "         [[ 0.1884]],\n",
      "\n",
      "         [[-1.9086]],\n",
      "\n",
      "         [[ 0.7974]],\n",
      "\n",
      "         [[-0.8599]],\n",
      "\n",
      "         [[ 0.9852]],\n",
      "\n",
      "         [[ 0.0464]],\n",
      "\n",
      "         [[ 0.4254]],\n",
      "\n",
      "         [[ 0.8332]],\n",
      "\n",
      "         [[-1.6412]],\n",
      "\n",
      "         [[-0.3031]],\n",
      "\n",
      "         [[-0.6356]],\n",
      "\n",
      "         [[-1.5050]]]], device='cuda:1')\n",
      "tensor([[[[ 0.1604]],\n",
      "\n",
      "         [[ 0.1245]],\n",
      "\n",
      "         [[-0.9985]],\n",
      "\n",
      "         [[ 0.2598]],\n",
      "\n",
      "         [[-0.8552]],\n",
      "\n",
      "         [[ 1.0170]],\n",
      "\n",
      "         [[-0.2552]],\n",
      "\n",
      "         [[-0.1404]],\n",
      "\n",
      "         [[-0.8615]],\n",
      "\n",
      "         [[-1.4495]],\n",
      "\n",
      "         [[-0.9703]],\n",
      "\n",
      "         [[-0.2901]],\n",
      "\n",
      "         [[ 0.7199]],\n",
      "\n",
      "         [[-1.2724]],\n",
      "\n",
      "         [[ 1.9020]],\n",
      "\n",
      "         [[-0.7184]],\n",
      "\n",
      "         [[-1.1877]],\n",
      "\n",
      "         [[ 0.3122]],\n",
      "\n",
      "         [[-0.2788]],\n",
      "\n",
      "         [[ 0.7421]],\n",
      "\n",
      "         [[ 0.0745]],\n",
      "\n",
      "         [[ 0.4578]],\n",
      "\n",
      "         [[ 2.2231]],\n",
      "\n",
      "         [[-0.6873]],\n",
      "\n",
      "         [[ 1.4260]],\n",
      "\n",
      "         [[ 0.3824]],\n",
      "\n",
      "         [[-0.3532]],\n",
      "\n",
      "         [[ 0.4525]],\n",
      "\n",
      "         [[ 0.3056]],\n",
      "\n",
      "         [[ 1.4913]],\n",
      "\n",
      "         [[ 0.1267]],\n",
      "\n",
      "         [[ 1.5414]],\n",
      "\n",
      "         [[-0.2093]],\n",
      "\n",
      "         [[-0.5287]],\n",
      "\n",
      "         [[ 2.3919]],\n",
      "\n",
      "         [[ 1.4469]],\n",
      "\n",
      "         [[ 1.5847]],\n",
      "\n",
      "         [[ 0.7280]],\n",
      "\n",
      "         [[-0.7233]],\n",
      "\n",
      "         [[-0.6280]],\n",
      "\n",
      "         [[ 0.9288]],\n",
      "\n",
      "         [[ 1.6599]],\n",
      "\n",
      "         [[-1.0745]],\n",
      "\n",
      "         [[ 1.0566]],\n",
      "\n",
      "         [[-1.2020]],\n",
      "\n",
      "         [[-1.6538]],\n",
      "\n",
      "         [[ 0.2633]],\n",
      "\n",
      "         [[-0.6765]],\n",
      "\n",
      "         [[-0.0963]],\n",
      "\n",
      "         [[-0.7831]],\n",
      "\n",
      "         [[ 0.1484]],\n",
      "\n",
      "         [[-0.5006]],\n",
      "\n",
      "         [[ 0.0908]],\n",
      "\n",
      "         [[ 0.8021]],\n",
      "\n",
      "         [[ 0.3802]],\n",
      "\n",
      "         [[-0.4772]],\n",
      "\n",
      "         [[ 0.4018]],\n",
      "\n",
      "         [[ 0.1422]],\n",
      "\n",
      "         [[ 1.2268]],\n",
      "\n",
      "         [[-0.3866]],\n",
      "\n",
      "         [[-0.8452]],\n",
      "\n",
      "         [[-0.5798]],\n",
      "\n",
      "         [[-0.0292]],\n",
      "\n",
      "         [[-0.2127]],\n",
      "\n",
      "         [[ 0.1621]],\n",
      "\n",
      "         [[-1.0529]],\n",
      "\n",
      "         [[ 1.3288]],\n",
      "\n",
      "         [[-0.6496]],\n",
      "\n",
      "         [[ 0.2419]],\n",
      "\n",
      "         [[ 1.6369]],\n",
      "\n",
      "         [[-0.6614]],\n",
      "\n",
      "         [[-0.0124]],\n",
      "\n",
      "         [[-0.6909]],\n",
      "\n",
      "         [[-0.5719]],\n",
      "\n",
      "         [[-0.2736]],\n",
      "\n",
      "         [[ 1.3826]],\n",
      "\n",
      "         [[-0.3309]],\n",
      "\n",
      "         [[ 1.2118]],\n",
      "\n",
      "         [[-1.4389]],\n",
      "\n",
      "         [[ 0.6538]],\n",
      "\n",
      "         [[ 1.2215]],\n",
      "\n",
      "         [[-1.8834]],\n",
      "\n",
      "         [[-0.6786]],\n",
      "\n",
      "         [[ 1.8717]],\n",
      "\n",
      "         [[-0.3273]],\n",
      "\n",
      "         [[-1.0000]],\n",
      "\n",
      "         [[-0.0945]],\n",
      "\n",
      "         [[ 0.5366]],\n",
      "\n",
      "         [[-0.6505]],\n",
      "\n",
      "         [[-1.6461]],\n",
      "\n",
      "         [[-0.5871]],\n",
      "\n",
      "         [[ 0.9189]],\n",
      "\n",
      "         [[-1.3365]],\n",
      "\n",
      "         [[-0.8203]],\n",
      "\n",
      "         [[-0.7872]],\n",
      "\n",
      "         [[ 1.6224]],\n",
      "\n",
      "         [[-0.2451]],\n",
      "\n",
      "         [[ 0.8590]],\n",
      "\n",
      "         [[-1.5818]],\n",
      "\n",
      "         [[-0.7461]]]], device='cuda:1')\n",
      "tensor([[[[ 1.2328]],\n",
      "\n",
      "         [[ 2.9870]],\n",
      "\n",
      "         [[ 0.9906]],\n",
      "\n",
      "         [[ 0.0672]],\n",
      "\n",
      "         [[ 0.1024]],\n",
      "\n",
      "         [[ 0.3069]],\n",
      "\n",
      "         [[-0.2045]],\n",
      "\n",
      "         [[ 1.8616]],\n",
      "\n",
      "         [[ 1.9278]],\n",
      "\n",
      "         [[-0.6374]],\n",
      "\n",
      "         [[ 0.0549]],\n",
      "\n",
      "         [[-0.1721]],\n",
      "\n",
      "         [[ 0.2835]],\n",
      "\n",
      "         [[-1.7363]],\n",
      "\n",
      "         [[ 2.6019]],\n",
      "\n",
      "         [[ 0.9043]],\n",
      "\n",
      "         [[-0.5815]],\n",
      "\n",
      "         [[-0.9247]],\n",
      "\n",
      "         [[-0.7516]],\n",
      "\n",
      "         [[ 0.2916]],\n",
      "\n",
      "         [[-0.2426]],\n",
      "\n",
      "         [[ 1.5801]],\n",
      "\n",
      "         [[-0.6841]],\n",
      "\n",
      "         [[ 1.3243]],\n",
      "\n",
      "         [[-1.8523]],\n",
      "\n",
      "         [[-1.2157]],\n",
      "\n",
      "         [[ 0.1864]],\n",
      "\n",
      "         [[ 0.7073]],\n",
      "\n",
      "         [[ 0.4586]],\n",
      "\n",
      "         [[ 0.2656]],\n",
      "\n",
      "         [[ 0.1011]],\n",
      "\n",
      "         [[ 1.0222]],\n",
      "\n",
      "         [[-2.6612]],\n",
      "\n",
      "         [[-0.6508]],\n",
      "\n",
      "         [[-0.6903]],\n",
      "\n",
      "         [[-0.7578]],\n",
      "\n",
      "         [[ 0.3037]],\n",
      "\n",
      "         [[-0.5928]],\n",
      "\n",
      "         [[ 1.1848]],\n",
      "\n",
      "         [[ 0.6228]],\n",
      "\n",
      "         [[ 1.1094]],\n",
      "\n",
      "         [[-0.7238]],\n",
      "\n",
      "         [[-1.2261]],\n",
      "\n",
      "         [[-1.3533]],\n",
      "\n",
      "         [[ 1.0914]],\n",
      "\n",
      "         [[ 2.3880]],\n",
      "\n",
      "         [[ 0.9263]],\n",
      "\n",
      "         [[ 1.1749]],\n",
      "\n",
      "         [[-0.1376]],\n",
      "\n",
      "         [[-0.2465]],\n",
      "\n",
      "         [[ 0.5080]],\n",
      "\n",
      "         [[-2.4238]],\n",
      "\n",
      "         [[-1.1058]],\n",
      "\n",
      "         [[-0.2124]],\n",
      "\n",
      "         [[ 1.5720]],\n",
      "\n",
      "         [[ 2.5603]],\n",
      "\n",
      "         [[ 2.3984]],\n",
      "\n",
      "         [[ 0.4630]],\n",
      "\n",
      "         [[ 0.3025]],\n",
      "\n",
      "         [[-0.7613]],\n",
      "\n",
      "         [[-0.9117]],\n",
      "\n",
      "         [[ 0.7201]],\n",
      "\n",
      "         [[-3.2169]],\n",
      "\n",
      "         [[-1.2417]],\n",
      "\n",
      "         [[-0.1841]],\n",
      "\n",
      "         [[ 0.2572]],\n",
      "\n",
      "         [[ 1.5469]],\n",
      "\n",
      "         [[-0.9692]],\n",
      "\n",
      "         [[-0.7872]],\n",
      "\n",
      "         [[ 0.9632]],\n",
      "\n",
      "         [[ 0.6665]],\n",
      "\n",
      "         [[-0.9595]],\n",
      "\n",
      "         [[ 1.8482]],\n",
      "\n",
      "         [[-0.2807]],\n",
      "\n",
      "         [[-0.8259]],\n",
      "\n",
      "         [[ 0.1223]],\n",
      "\n",
      "         [[ 0.4316]],\n",
      "\n",
      "         [[-0.1569]],\n",
      "\n",
      "         [[-0.1720]],\n",
      "\n",
      "         [[ 0.0128]],\n",
      "\n",
      "         [[ 1.1909]],\n",
      "\n",
      "         [[-0.1190]],\n",
      "\n",
      "         [[-0.4612]],\n",
      "\n",
      "         [[ 1.2379]],\n",
      "\n",
      "         [[ 0.0325]],\n",
      "\n",
      "         [[-2.0732]],\n",
      "\n",
      "         [[ 0.1932]],\n",
      "\n",
      "         [[ 1.1914]],\n",
      "\n",
      "         [[ 0.3921]],\n",
      "\n",
      "         [[ 1.4084]],\n",
      "\n",
      "         [[-1.8809]],\n",
      "\n",
      "         [[-0.2778]],\n",
      "\n",
      "         [[ 0.3023]],\n",
      "\n",
      "         [[ 1.2740]],\n",
      "\n",
      "         [[-0.0774]],\n",
      "\n",
      "         [[-0.2142]],\n",
      "\n",
      "         [[ 0.0842]],\n",
      "\n",
      "         [[ 0.1301]],\n",
      "\n",
      "         [[ 0.3208]],\n",
      "\n",
      "         [[-1.2486]]]], device='cuda:1')\n",
      "tensor([[[[ 1.6118]],\n",
      "\n",
      "         [[ 1.1416]],\n",
      "\n",
      "         [[ 0.4344]],\n",
      "\n",
      "         [[ 0.6671]],\n",
      "\n",
      "         [[ 0.0290]],\n",
      "\n",
      "         [[-0.5867]],\n",
      "\n",
      "         [[-1.8944]],\n",
      "\n",
      "         [[ 0.3447]],\n",
      "\n",
      "         [[ 0.1963]],\n",
      "\n",
      "         [[ 1.4554]],\n",
      "\n",
      "         [[-1.6716]],\n",
      "\n",
      "         [[-1.2826]],\n",
      "\n",
      "         [[ 0.2702]],\n",
      "\n",
      "         [[-1.6839]],\n",
      "\n",
      "         [[-0.3907]],\n",
      "\n",
      "         [[-0.4144]],\n",
      "\n",
      "         [[-0.5644]],\n",
      "\n",
      "         [[ 0.2909]],\n",
      "\n",
      "         [[ 0.1281]],\n",
      "\n",
      "         [[-1.5540]],\n",
      "\n",
      "         [[-0.8890]],\n",
      "\n",
      "         [[-1.3359]],\n",
      "\n",
      "         [[ 1.7641]],\n",
      "\n",
      "         [[ 0.2358]],\n",
      "\n",
      "         [[-0.3121]],\n",
      "\n",
      "         [[ 0.3430]],\n",
      "\n",
      "         [[-1.5058]],\n",
      "\n",
      "         [[ 0.9130]],\n",
      "\n",
      "         [[ 0.9062]],\n",
      "\n",
      "         [[-0.1704]],\n",
      "\n",
      "         [[-0.2735]],\n",
      "\n",
      "         [[ 1.8543]],\n",
      "\n",
      "         [[ 1.6041]],\n",
      "\n",
      "         [[-1.5407]],\n",
      "\n",
      "         [[ 2.2549]],\n",
      "\n",
      "         [[ 0.5173]],\n",
      "\n",
      "         [[ 0.9148]],\n",
      "\n",
      "         [[-0.7404]],\n",
      "\n",
      "         [[-1.0953]],\n",
      "\n",
      "         [[-0.9296]],\n",
      "\n",
      "         [[ 0.4370]],\n",
      "\n",
      "         [[-0.7215]],\n",
      "\n",
      "         [[-1.6404]],\n",
      "\n",
      "         [[-1.8871]],\n",
      "\n",
      "         [[-1.4626]],\n",
      "\n",
      "         [[-0.2414]],\n",
      "\n",
      "         [[ 0.7933]],\n",
      "\n",
      "         [[ 0.4869]],\n",
      "\n",
      "         [[-0.3957]],\n",
      "\n",
      "         [[ 1.6560]],\n",
      "\n",
      "         [[-0.3525]],\n",
      "\n",
      "         [[ 1.7498]],\n",
      "\n",
      "         [[-0.4185]],\n",
      "\n",
      "         [[ 0.7831]],\n",
      "\n",
      "         [[ 0.1025]],\n",
      "\n",
      "         [[ 0.7045]],\n",
      "\n",
      "         [[-0.8183]],\n",
      "\n",
      "         [[ 1.0782]],\n",
      "\n",
      "         [[ 1.3711]],\n",
      "\n",
      "         [[ 0.2623]],\n",
      "\n",
      "         [[ 1.1498]],\n",
      "\n",
      "         [[-1.5904]],\n",
      "\n",
      "         [[ 2.1543]],\n",
      "\n",
      "         [[ 0.2279]],\n",
      "\n",
      "         [[ 0.1760]],\n",
      "\n",
      "         [[-1.9685]],\n",
      "\n",
      "         [[ 0.1327]],\n",
      "\n",
      "         [[-0.3589]],\n",
      "\n",
      "         [[-1.1923]],\n",
      "\n",
      "         [[ 0.7500]],\n",
      "\n",
      "         [[-0.5932]],\n",
      "\n",
      "         [[-0.1509]],\n",
      "\n",
      "         [[ 0.0290]],\n",
      "\n",
      "         [[-1.6110]],\n",
      "\n",
      "         [[-1.6117]],\n",
      "\n",
      "         [[-0.0421]],\n",
      "\n",
      "         [[-0.6837]],\n",
      "\n",
      "         [[ 0.5041]],\n",
      "\n",
      "         [[ 1.2809]],\n",
      "\n",
      "         [[ 0.1013]],\n",
      "\n",
      "         [[ 0.1899]],\n",
      "\n",
      "         [[-0.8794]],\n",
      "\n",
      "         [[ 1.4877]],\n",
      "\n",
      "         [[-0.1569]],\n",
      "\n",
      "         [[ 1.6268]],\n",
      "\n",
      "         [[-0.9073]],\n",
      "\n",
      "         [[ 0.4778]],\n",
      "\n",
      "         [[-0.3985]],\n",
      "\n",
      "         [[ 1.6257]],\n",
      "\n",
      "         [[-0.4464]],\n",
      "\n",
      "         [[-1.2537]],\n",
      "\n",
      "         [[-0.4179]],\n",
      "\n",
      "         [[-0.0890]],\n",
      "\n",
      "         [[-0.0287]],\n",
      "\n",
      "         [[-1.3451]],\n",
      "\n",
      "         [[-1.4866]],\n",
      "\n",
      "         [[-0.7354]],\n",
      "\n",
      "         [[-0.0155]],\n",
      "\n",
      "         [[-0.7452]],\n",
      "\n",
      "         [[ 2.1171]]]], device='cuda:1')\n",
      "tensor([[[[-1.3318]],\n",
      "\n",
      "         [[-0.9835]],\n",
      "\n",
      "         [[-1.6137]],\n",
      "\n",
      "         [[-1.7316]],\n",
      "\n",
      "         [[-0.7004]],\n",
      "\n",
      "         [[ 1.0337]],\n",
      "\n",
      "         [[ 0.3739]],\n",
      "\n",
      "         [[ 1.0946]],\n",
      "\n",
      "         [[-0.2934]],\n",
      "\n",
      "         [[-0.3693]],\n",
      "\n",
      "         [[ 0.0176]],\n",
      "\n",
      "         [[ 0.5321]],\n",
      "\n",
      "         [[ 1.8600]],\n",
      "\n",
      "         [[-0.7626]],\n",
      "\n",
      "         [[-1.5155]],\n",
      "\n",
      "         [[ 0.1653]],\n",
      "\n",
      "         [[ 1.0219]],\n",
      "\n",
      "         [[ 0.9134]],\n",
      "\n",
      "         [[ 2.3198]],\n",
      "\n",
      "         [[-0.1872]],\n",
      "\n",
      "         [[ 0.6832]],\n",
      "\n",
      "         [[-0.7666]],\n",
      "\n",
      "         [[ 0.5552]],\n",
      "\n",
      "         [[ 0.6115]],\n",
      "\n",
      "         [[-1.3707]],\n",
      "\n",
      "         [[-0.8825]],\n",
      "\n",
      "         [[ 0.5166]],\n",
      "\n",
      "         [[ 1.6937]],\n",
      "\n",
      "         [[-0.6539]],\n",
      "\n",
      "         [[-0.4103]],\n",
      "\n",
      "         [[ 0.9519]],\n",
      "\n",
      "         [[-1.1576]],\n",
      "\n",
      "         [[-1.6388]],\n",
      "\n",
      "         [[-1.0736]],\n",
      "\n",
      "         [[-0.8335]],\n",
      "\n",
      "         [[ 1.4726]],\n",
      "\n",
      "         [[ 1.2186]],\n",
      "\n",
      "         [[-1.4837]],\n",
      "\n",
      "         [[-1.7076]],\n",
      "\n",
      "         [[ 1.0901]],\n",
      "\n",
      "         [[ 0.3268]],\n",
      "\n",
      "         [[-0.4618]],\n",
      "\n",
      "         [[ 1.0056]],\n",
      "\n",
      "         [[ 0.3626]],\n",
      "\n",
      "         [[-0.8197]],\n",
      "\n",
      "         [[-0.4989]],\n",
      "\n",
      "         [[ 0.0630]],\n",
      "\n",
      "         [[-0.9619]],\n",
      "\n",
      "         [[-0.8061]],\n",
      "\n",
      "         [[ 0.7817]],\n",
      "\n",
      "         [[ 0.6625]],\n",
      "\n",
      "         [[-1.1489]],\n",
      "\n",
      "         [[ 0.3492]],\n",
      "\n",
      "         [[-1.3884]],\n",
      "\n",
      "         [[-2.1295]],\n",
      "\n",
      "         [[-1.1204]],\n",
      "\n",
      "         [[-0.3717]],\n",
      "\n",
      "         [[ 2.0006]],\n",
      "\n",
      "         [[ 1.0194]],\n",
      "\n",
      "         [[-0.7437]],\n",
      "\n",
      "         [[-0.4349]],\n",
      "\n",
      "         [[-1.9332]],\n",
      "\n",
      "         [[-1.1922]],\n",
      "\n",
      "         [[ 0.4088]],\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         [[ 2.3977]],\n",
      "\n",
      "         [[-0.5918]],\n",
      "\n",
      "         [[ 0.1928]],\n",
      "\n",
      "         [[ 0.5204]],\n",
      "\n",
      "         [[ 0.8319]],\n",
      "\n",
      "         [[-0.7603]],\n",
      "\n",
      "         [[ 0.4777]],\n",
      "\n",
      "         [[ 0.7666]],\n",
      "\n",
      "         [[ 0.0565]],\n",
      "\n",
      "         [[ 1.3885]],\n",
      "\n",
      "         [[-0.2951]],\n",
      "\n",
      "         [[ 0.5191]],\n",
      "\n",
      "         [[ 2.1176]],\n",
      "\n",
      "         [[ 0.0835]],\n",
      "\n",
      "         [[ 0.7584]],\n",
      "\n",
      "         [[-0.3561]],\n",
      "\n",
      "         [[-0.2105]],\n",
      "\n",
      "         [[ 0.8409]],\n",
      "\n",
      "         [[ 1.1763]],\n",
      "\n",
      "         [[-0.3095]],\n",
      "\n",
      "         [[-0.6358]],\n",
      "\n",
      "         [[ 1.1303]],\n",
      "\n",
      "         [[ 0.2630]],\n",
      "\n",
      "         [[-1.3395]],\n",
      "\n",
      "         [[-0.3450]],\n",
      "\n",
      "         [[ 0.1874]],\n",
      "\n",
      "         [[ 1.3154]],\n",
      "\n",
      "         [[ 0.0927]],\n",
      "\n",
      "         [[ 1.1249]],\n",
      "\n",
      "         [[ 0.5220]],\n",
      "\n",
      "         [[ 0.2029]],\n",
      "\n",
      "         [[-0.2601]],\n",
      "\n",
      "         [[-2.1752]],\n",
      "\n",
      "         [[-0.6866]],\n",
      "\n",
      "         [[ 1.0393]]]], device='cuda:1')\n",
      "tensor([[[[-1.5924]],\n",
      "\n",
      "         [[ 0.4604]],\n",
      "\n",
      "         [[ 0.1555]],\n",
      "\n",
      "         [[-0.3452]],\n",
      "\n",
      "         [[ 0.0923]],\n",
      "\n",
      "         [[ 0.1525]],\n",
      "\n",
      "         [[-0.0775]],\n",
      "\n",
      "         [[ 0.1486]],\n",
      "\n",
      "         [[-1.8463]],\n",
      "\n",
      "         [[-1.9958]],\n",
      "\n",
      "         [[-0.7485]],\n",
      "\n",
      "         [[-1.0298]],\n",
      "\n",
      "         [[ 0.0042]],\n",
      "\n",
      "         [[ 0.6063]],\n",
      "\n",
      "         [[ 0.7967]],\n",
      "\n",
      "         [[ 0.7529]],\n",
      "\n",
      "         [[-0.1046]],\n",
      "\n",
      "         [[-1.3666]],\n",
      "\n",
      "         [[ 0.5034]],\n",
      "\n",
      "         [[ 0.0604]],\n",
      "\n",
      "         [[-0.8610]],\n",
      "\n",
      "         [[ 1.3452]],\n",
      "\n",
      "         [[-0.4659]],\n",
      "\n",
      "         [[-0.5486]],\n",
      "\n",
      "         [[-0.8162]],\n",
      "\n",
      "         [[ 0.1894]],\n",
      "\n",
      "         [[-0.6376]],\n",
      "\n",
      "         [[-1.1450]],\n",
      "\n",
      "         [[-1.4091]],\n",
      "\n",
      "         [[ 0.5862]],\n",
      "\n",
      "         [[-1.3258]],\n",
      "\n",
      "         [[-1.0415]],\n",
      "\n",
      "         [[-0.7509]],\n",
      "\n",
      "         [[-0.5694]],\n",
      "\n",
      "         [[-1.0690]],\n",
      "\n",
      "         [[-0.7659]],\n",
      "\n",
      "         [[-1.0075]],\n",
      "\n",
      "         [[ 0.6357]],\n",
      "\n",
      "         [[-1.5687]],\n",
      "\n",
      "         [[-1.1110]],\n",
      "\n",
      "         [[-1.4095]],\n",
      "\n",
      "         [[-1.4170]],\n",
      "\n",
      "         [[ 0.0765]],\n",
      "\n",
      "         [[-0.3455]],\n",
      "\n",
      "         [[-0.4728]],\n",
      "\n",
      "         [[ 0.9198]],\n",
      "\n",
      "         [[ 0.5452]],\n",
      "\n",
      "         [[ 1.8203]],\n",
      "\n",
      "         [[ 0.1314]],\n",
      "\n",
      "         [[-0.3202]],\n",
      "\n",
      "         [[ 0.7212]],\n",
      "\n",
      "         [[-0.1740]],\n",
      "\n",
      "         [[-1.0628]],\n",
      "\n",
      "         [[ 0.1633]],\n",
      "\n",
      "         [[-0.6050]],\n",
      "\n",
      "         [[-0.4619]],\n",
      "\n",
      "         [[ 0.3167]],\n",
      "\n",
      "         [[ 0.1761]],\n",
      "\n",
      "         [[-2.1547]],\n",
      "\n",
      "         [[ 0.0056]],\n",
      "\n",
      "         [[-0.9892]],\n",
      "\n",
      "         [[-0.1989]],\n",
      "\n",
      "         [[ 0.3016]],\n",
      "\n",
      "         [[ 1.2994]],\n",
      "\n",
      "         [[ 0.6701]],\n",
      "\n",
      "         [[-0.6366]],\n",
      "\n",
      "         [[-0.7179]],\n",
      "\n",
      "         [[-1.7144]],\n",
      "\n",
      "         [[ 1.0443]],\n",
      "\n",
      "         [[-2.4673]],\n",
      "\n",
      "         [[ 2.1977]],\n",
      "\n",
      "         [[-1.9305]],\n",
      "\n",
      "         [[-0.5539]],\n",
      "\n",
      "         [[ 0.3447]],\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[-0.2115]],\n",
      "\n",
      "         [[ 1.1377]],\n",
      "\n",
      "         [[-1.1666]],\n",
      "\n",
      "         [[ 0.4168]],\n",
      "\n",
      "         [[ 2.1140]],\n",
      "\n",
      "         [[ 0.7145]],\n",
      "\n",
      "         [[-1.0510]],\n",
      "\n",
      "         [[ 0.1617]],\n",
      "\n",
      "         [[-1.8141]],\n",
      "\n",
      "         [[ 0.0358]],\n",
      "\n",
      "         [[ 1.4005]],\n",
      "\n",
      "         [[-0.7029]],\n",
      "\n",
      "         [[ 1.4166]],\n",
      "\n",
      "         [[ 1.3613]],\n",
      "\n",
      "         [[-0.4050]],\n",
      "\n",
      "         [[-0.2062]],\n",
      "\n",
      "         [[ 1.7074]],\n",
      "\n",
      "         [[ 1.0254]],\n",
      "\n",
      "         [[-0.7540]],\n",
      "\n",
      "         [[ 0.3896]],\n",
      "\n",
      "         [[-0.0373]],\n",
      "\n",
      "         [[-0.1894]],\n",
      "\n",
      "         [[-0.6805]],\n",
      "\n",
      "         [[ 0.0948]],\n",
      "\n",
      "         [[ 0.4312]]]], device='cuda:1')\n",
      "tensor([[[[-0.4722]],\n",
      "\n",
      "         [[-0.4738]],\n",
      "\n",
      "         [[ 0.0693]],\n",
      "\n",
      "         [[-0.2125]],\n",
      "\n",
      "         [[ 0.8434]],\n",
      "\n",
      "         [[ 0.3186]],\n",
      "\n",
      "         [[-0.9270]],\n",
      "\n",
      "         [[ 1.7887]],\n",
      "\n",
      "         [[ 0.2097]],\n",
      "\n",
      "         [[-1.1287]],\n",
      "\n",
      "         [[ 1.5402]],\n",
      "\n",
      "         [[ 0.8031]],\n",
      "\n",
      "         [[ 0.3464]],\n",
      "\n",
      "         [[-0.4877]],\n",
      "\n",
      "         [[-0.0568]],\n",
      "\n",
      "         [[-0.3797]],\n",
      "\n",
      "         [[-1.7266]],\n",
      "\n",
      "         [[-0.3689]],\n",
      "\n",
      "         [[ 1.1788]],\n",
      "\n",
      "         [[-1.1200]],\n",
      "\n",
      "         [[ 0.4813]],\n",
      "\n",
      "         [[ 1.0022]],\n",
      "\n",
      "         [[-0.5954]],\n",
      "\n",
      "         [[ 0.7653]],\n",
      "\n",
      "         [[-1.2053]],\n",
      "\n",
      "         [[ 0.3508]],\n",
      "\n",
      "         [[-1.4048]],\n",
      "\n",
      "         [[-1.8842]],\n",
      "\n",
      "         [[-0.3314]],\n",
      "\n",
      "         [[ 1.7503]],\n",
      "\n",
      "         [[-0.7154]],\n",
      "\n",
      "         [[-0.1876]],\n",
      "\n",
      "         [[-0.4674]],\n",
      "\n",
      "         [[-0.2873]],\n",
      "\n",
      "         [[-0.9920]],\n",
      "\n",
      "         [[ 0.1764]],\n",
      "\n",
      "         [[-0.6026]],\n",
      "\n",
      "         [[ 0.7732]],\n",
      "\n",
      "         [[ 2.8029]],\n",
      "\n",
      "         [[ 0.4644]],\n",
      "\n",
      "         [[-0.2797]],\n",
      "\n",
      "         [[-1.0507]],\n",
      "\n",
      "         [[ 0.7684]],\n",
      "\n",
      "         [[ 0.2970]],\n",
      "\n",
      "         [[-0.2439]],\n",
      "\n",
      "         [[-1.0047]],\n",
      "\n",
      "         [[ 0.8700]],\n",
      "\n",
      "         [[ 0.9338]],\n",
      "\n",
      "         [[-0.8644]],\n",
      "\n",
      "         [[ 1.7257]],\n",
      "\n",
      "         [[-0.5801]],\n",
      "\n",
      "         [[ 1.1654]],\n",
      "\n",
      "         [[ 1.6372]],\n",
      "\n",
      "         [[ 1.0407]],\n",
      "\n",
      "         [[-1.0023]],\n",
      "\n",
      "         [[-0.1194]],\n",
      "\n",
      "         [[ 0.4173]],\n",
      "\n",
      "         [[ 0.5656]],\n",
      "\n",
      "         [[ 0.0416]],\n",
      "\n",
      "         [[-0.3424]],\n",
      "\n",
      "         [[ 0.2738]],\n",
      "\n",
      "         [[ 0.0669]],\n",
      "\n",
      "         [[-0.8232]],\n",
      "\n",
      "         [[ 0.3381]],\n",
      "\n",
      "         [[ 1.3711]],\n",
      "\n",
      "         [[-0.7542]],\n",
      "\n",
      "         [[-1.5361]],\n",
      "\n",
      "         [[ 0.2522]],\n",
      "\n",
      "         [[ 0.8302]],\n",
      "\n",
      "         [[-0.8249]],\n",
      "\n",
      "         [[ 0.3030]],\n",
      "\n",
      "         [[-0.2580]],\n",
      "\n",
      "         [[ 0.3966]],\n",
      "\n",
      "         [[ 0.7951]],\n",
      "\n",
      "         [[-1.2409]],\n",
      "\n",
      "         [[ 0.4001]],\n",
      "\n",
      "         [[-0.6385]],\n",
      "\n",
      "         [[ 0.3008]],\n",
      "\n",
      "         [[ 0.9565]],\n",
      "\n",
      "         [[-0.5880]],\n",
      "\n",
      "         [[ 0.1351]],\n",
      "\n",
      "         [[-1.2480]],\n",
      "\n",
      "         [[-0.7529]],\n",
      "\n",
      "         [[-0.8482]],\n",
      "\n",
      "         [[ 0.2891]],\n",
      "\n",
      "         [[-0.0485]],\n",
      "\n",
      "         [[-0.0274]],\n",
      "\n",
      "         [[-0.8841]],\n",
      "\n",
      "         [[-0.9119]],\n",
      "\n",
      "         [[-0.4612]],\n",
      "\n",
      "         [[-0.8646]],\n",
      "\n",
      "         [[-0.0853]],\n",
      "\n",
      "         [[ 0.8835]],\n",
      "\n",
      "         [[ 0.2504]],\n",
      "\n",
      "         [[-1.7230]],\n",
      "\n",
      "         [[ 1.6954]],\n",
      "\n",
      "         [[-0.1100]],\n",
      "\n",
      "         [[ 0.7697]],\n",
      "\n",
      "         [[-1.0313]],\n",
      "\n",
      "         [[ 0.6080]]]], device='cuda:1')\n",
      "tensor([[[[ 0.4504]],\n",
      "\n",
      "         [[ 1.5008]],\n",
      "\n",
      "         [[ 0.1250]],\n",
      "\n",
      "         [[ 1.7770]],\n",
      "\n",
      "         [[ 0.6879]],\n",
      "\n",
      "         [[ 0.8092]],\n",
      "\n",
      "         [[ 1.7396]],\n",
      "\n",
      "         [[ 1.1016]],\n",
      "\n",
      "         [[-0.9539]],\n",
      "\n",
      "         [[ 2.0801]],\n",
      "\n",
      "         [[ 0.7961]],\n",
      "\n",
      "         [[ 0.9409]],\n",
      "\n",
      "         [[ 0.5355]],\n",
      "\n",
      "         [[-0.0878]],\n",
      "\n",
      "         [[-0.1760]],\n",
      "\n",
      "         [[ 0.8544]],\n",
      "\n",
      "         [[ 0.3742]],\n",
      "\n",
      "         [[ 0.2705]],\n",
      "\n",
      "         [[-0.8886]],\n",
      "\n",
      "         [[-0.5319]],\n",
      "\n",
      "         [[ 0.5472]],\n",
      "\n",
      "         [[-0.1666]],\n",
      "\n",
      "         [[-0.3484]],\n",
      "\n",
      "         [[ 0.1609]],\n",
      "\n",
      "         [[ 0.6210]],\n",
      "\n",
      "         [[-0.1970]],\n",
      "\n",
      "         [[ 0.0681]],\n",
      "\n",
      "         [[ 0.3473]],\n",
      "\n",
      "         [[-0.7670]],\n",
      "\n",
      "         [[ 1.0956]],\n",
      "\n",
      "         [[-1.0535]],\n",
      "\n",
      "         [[-0.1093]],\n",
      "\n",
      "         [[-0.6894]],\n",
      "\n",
      "         [[-0.1567]],\n",
      "\n",
      "         [[-1.3141]],\n",
      "\n",
      "         [[ 0.4609]],\n",
      "\n",
      "         [[-1.0430]],\n",
      "\n",
      "         [[ 0.2684]],\n",
      "\n",
      "         [[-0.5118]],\n",
      "\n",
      "         [[ 0.8795]],\n",
      "\n",
      "         [[ 2.0244]],\n",
      "\n",
      "         [[-0.7726]],\n",
      "\n",
      "         [[-0.8960]],\n",
      "\n",
      "         [[-0.2024]],\n",
      "\n",
      "         [[-0.6086]],\n",
      "\n",
      "         [[-0.1777]],\n",
      "\n",
      "         [[ 0.0221]],\n",
      "\n",
      "         [[-0.8540]],\n",
      "\n",
      "         [[-0.8340]],\n",
      "\n",
      "         [[-1.6385]],\n",
      "\n",
      "         [[ 2.0164]],\n",
      "\n",
      "         [[-1.0181]],\n",
      "\n",
      "         [[ 0.6942]],\n",
      "\n",
      "         [[ 0.5460]],\n",
      "\n",
      "         [[ 1.2822]],\n",
      "\n",
      "         [[ 0.5878]],\n",
      "\n",
      "         [[-0.7437]],\n",
      "\n",
      "         [[ 0.3715]],\n",
      "\n",
      "         [[-0.1100]],\n",
      "\n",
      "         [[ 0.2785]],\n",
      "\n",
      "         [[-1.4155]],\n",
      "\n",
      "         [[-0.6124]],\n",
      "\n",
      "         [[ 1.3320]],\n",
      "\n",
      "         [[-0.8166]],\n",
      "\n",
      "         [[ 0.5836]],\n",
      "\n",
      "         [[-0.9679]],\n",
      "\n",
      "         [[-1.6005]],\n",
      "\n",
      "         [[-0.1368]],\n",
      "\n",
      "         [[ 1.3401]],\n",
      "\n",
      "         [[-0.6901]],\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         [[ 0.7585]],\n",
      "\n",
      "         [[ 0.8219]],\n",
      "\n",
      "         [[ 0.1414]],\n",
      "\n",
      "         [[ 0.4317]],\n",
      "\n",
      "         [[-0.0807]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[-0.9811]],\n",
      "\n",
      "         [[ 0.2207]],\n",
      "\n",
      "         [[-1.2513]],\n",
      "\n",
      "         [[-1.2015]],\n",
      "\n",
      "         [[ 2.4047]],\n",
      "\n",
      "         [[-0.1471]],\n",
      "\n",
      "         [[-0.9347]],\n",
      "\n",
      "         [[-0.1090]],\n",
      "\n",
      "         [[-0.1008]],\n",
      "\n",
      "         [[-0.0927]],\n",
      "\n",
      "         [[-0.5054]],\n",
      "\n",
      "         [[-0.0135]],\n",
      "\n",
      "         [[ 0.0893]],\n",
      "\n",
      "         [[ 2.7211]],\n",
      "\n",
      "         [[-0.7450]],\n",
      "\n",
      "         [[ 0.6326]],\n",
      "\n",
      "         [[ 0.1067]],\n",
      "\n",
      "         [[ 1.4244]],\n",
      "\n",
      "         [[ 0.9661]],\n",
      "\n",
      "         [[ 0.4236]],\n",
      "\n",
      "         [[-0.1181]],\n",
      "\n",
      "         [[ 0.8653]],\n",
      "\n",
      "         [[ 0.8447]]]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(999)\n",
    "for i in range(10):\n",
    "    fixed_noise = torch.randn(1, nz, 1, 1, device=device)\n",
    "    print(fixed_noise)\n",
    "    fake = netG(fixed_noise)\n",
    "    vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % ('.', i),\n",
    "                    normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
